import torch
import cv2
import numpy as np
import requests
from PIL import Image
from io import BytesIO

def download_image(url):
    response = requests.get(url)
    image = Image.open(BytesIO(response.content))
    return cv2.cvtColor(np.array(image), cv2.COLOR_RGB2BGR)

def detect_fruits(image_url, model, class_names):
    # Descargar la imagen desde la URL
    img = download_image(image_url)
    
    # Realizar la detección
    results = model(img)
    
    # Dibujar las detecciones
    for detection in results.xyxy[0]:
        x1, y1, x2, y2, conf, class_id = detection.tolist()
        if conf > 0.5 and class_names[int(class_id)] in ['banana', 'apple', 'orange', 'pear']:
            cv2.rectangle(img, (int(x1), int(y1)), (int(x2), int(y2)), (0, 255, 0), 2)
            label = f'{class_names[int(class_id)]} {conf:.2f}'
            cv2.putText(img, label, (int(x1), int(y1) - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.9, (0, 255, 0), 2)
    
    return img, results

# Cargar el modelo YOLOv5 desde PyTorch Hub
model = torch.hub.load('ultralytics/yolov5', 'yolov5s', pretrained=True)

# Definir las clases que nos interesan
fruit_classes = ['banana', 'apple', 'orange', 'pear']

# Uso del detector
image_url = "https://elegifruta.com.ar/wp-content/uploads/2023/06/imagenpublinota-1A.png"
img_with_detections, result = detect_fruits(image_url, model, model.names)

# Mostrar la imagen con las detecciones
cv2.imshow("Detección de frutas", img_with_detections)
cv2.waitKey(0)
cv2.destroyAllWindows()

# Imprimir información sobre las detecciones
for detection in result.xyxy[0]:
    x1, y1, x2, y2, conf, class_id = detection.tolist()
    if conf > 0.5 and model.names[int(class_id)] in fruit_classes:
        print(f"Clase: {model.names[int(class_id)]}, Confianza: {conf:.2f}, Bounding Box: [{x1}, {y1}, {x2}, {y2}]")

# Guardar la imagen con las detecciones
cv2.imwrite("frutas_detectadas_yolov5.jpg", img_with_detections)